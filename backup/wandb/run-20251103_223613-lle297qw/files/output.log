Loading model in 4-bit...

============================================================
GPU PROCESS CHECK
============================================================
Mon Nov  3 22:39:07 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |
| N/A   75C    P0             32W /   70W |   11465MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |
| N/A   77C    P0             33W /   70W |    5387MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+


PyTorch GPU Memory:
GPU 0:
  Total: 14.74 GB
  Allocated: 9.83 GB
  Reserved: 10.74 GB
  Free: 4.91 GB
GPU 1:
  Total: 14.74 GB
  Allocated: 0.01 GB
  Reserved: 5.07 GB
  Free: 14.73 GB

============================================================
TENSORS ON GPU
============================================================
  Tensor: torch.Size([32768, 4096]), torch.bfloat16, 256.00 MB
  Tensor: torch.Size([4096]), torch.bfloat16, 0.01 MB
  Tensor: torch.Size([29360128, 1]), torch.uint8, 28.00 MB
  Tensor: torch.Size([29360128, 1]), torch.uint8, 28.00 MB
  Tensor: torch.Size([29360128, 1]), torch.uint8, 28.00 MB
  Tensor: torch.Size([4096]), torch.bfloat16, 0.01 MB
  Tensor: torch.Size([2097152, 1]), torch.uint8, 2.00 MB
  Tensor: torch.Size([8388608, 1]), torch.uint8, 8.00 MB
  Tensor: torch.Size([8388608, 1]), torch.uint8, 8.00 MB
  Tensor: torch.Size([2097152, 1]), torch.uint8, 2.00 MB
/usr/local/lib/python3.11/dist-packages/torch/__init__.py:1113: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)

Total GPU tensors: 1296
Total size: 10.03 GB
